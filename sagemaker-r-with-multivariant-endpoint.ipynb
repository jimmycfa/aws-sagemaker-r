{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using R with Amazon SageMaker</h1>\n",
    "\n",
    "This sample Notebook describes how to train, deploy, and retrieve predictions from a machine learning (ML) model using [Amazon SageMaker](https://aws.amazon.com/sagemaker/) and [R](https://www.r-project.org/). The model predicts abalone age as measured by the number of rings in the shell. The [reticulate](https://rstudio.github.io/reticulate/) package will be used as an R interface to [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/latest/index.html) to make API calls to Amazon SageMaker. The `reticulate` package translates between R and Python objects, and Amazon SageMaker provides a serverless data science environment to train and deploy ML models at scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reticulating the Amazon SageMaker Python SDK</h3>\n",
    "\n",
    "First, load the `reticulate` library and import the `sagemaker` Python module. Once the module is loaded, use the `$` notation in R instead of the `.` notation in Python to use available classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off globally\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"remotes\"\n",
      "[1] \"arules\"\n",
      "[1] \"bit64\"\n",
      "[1] \"caTools\"\n",
      "[1] \"combinat\"\n",
      "[1] \"data.table\"\n",
      "[1] \"doParallel\"\n",
      "[1] \"e1071\"\n",
      "[1] \"fBasics\"\n",
      "[1] \"foreach\"\n",
      "[1] \"forecast\"\n",
      "[1] \"fpp\"\n",
      "[1] \"ggplot2\"\n",
      "[1] \"gridExtra\"\n",
      "[1] \"here\"\n",
      "[1] \"itertools\"\n",
      "[1] \"lime\"\n",
      "[1] \"lubridate\"\n",
      "[1] \"Matrix\"\n",
      "[1] \"MLmetrics\"\n",
      "[1] \"monreg\"\n",
      "[1] \"nortest\"\n",
      "[1] \"RColorBrewer\"\n",
      "[1] \"recommenderlab\"\n",
      "[1] \"ROCR\"\n",
      "[1] \"pROC\"\n",
      "[1] \"Rcpp\"\n",
      "[1] \"scatterplot3d\"\n",
      "[1] \"stringr\"\n",
      "[1] \"sde\"\n",
      "[1] \"timeDate\"\n",
      "[1] \"tsoutliers\"\n",
      "[1] \"wordcloud\"\n",
      "[1] \"xgboost\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies----\n",
    "if(!(\"remotes\" %in% rownames(installed.packages()))) install.packages(\"remotes\"); print(\"remotes\")\n",
    "if(!(\"arules\" %in% rownames(installed.packages()))) install.packages(\"arules\"); print(\"arules\")\n",
    "if(!(\"bit64\" %in% rownames(installed.packages()))) install.packages(\"bit64\"); print(\"bit64\")\n",
    "if(!(\"caTools\" %in% rownames(installed.packages()))) install.packages(\"caTools\"); print(\"caTools\")\n",
    "if(!(\"combinat\" %in% rownames(installed.packages()))) install.packages(\"combinat\"); print(\"combinat\")\n",
    "if(!(\"data.table\" %in% rownames(installed.packages()))) install.packages(\"data.table\"); print(\"data.table\")\n",
    "if(!(\"doParallel\" %in% rownames(installed.packages()))) install.packages(\"doParallel\"); print(\"doParallel\")\n",
    "if(!(\"e1071\" %in% rownames(installed.packages()))) install.packages(\"e1071\"); print(\"e1071\")\n",
    "if(!(\"fBasics\" %in% rownames(installed.packages()))) install.packages(\"fBasics\"); print(\"fBasics\")\n",
    "if(!(\"foreach\" %in% rownames(installed.packages()))) install.packages(\"foreach\"); print(\"foreach\")\n",
    "if(!(\"forecast\" %in% rownames(installed.packages()))) install.packages(\"forecast\"); print(\"forecast\")\n",
    "if(!(\"fpp\" %in% rownames(installed.packages()))) install.packages(\"fpp\"); print(\"fpp\")\n",
    "if(!(\"ggplot2\" %in% rownames(installed.packages()))) install.packages(\"ggplot2\"); print(\"ggplot2\")\n",
    "if(!(\"gridExtra\" %in% rownames(installed.packages()))) install.packages(\"gridExtra\"); print(\"gridExtra\")\n",
    "if(!(\"here\" %in% rownames(installed.packages()))) install.packages(\"here\"); print(\"here\")\n",
    "if(!(\"itertools\" %in% rownames(installed.packages()))) install.packages(\"itertools\"); print(\"itertools\")\n",
    "if(!(\"lime\" %in% rownames(installed.packages()))) install.packages(\"lime\"); print(\"lime\")\n",
    "if(!(\"lubridate\" %in% rownames(installed.packages()))) install.packages(\"lubridate\"); print(\"lubridate\")\n",
    "if(!(\"Matrix\" %in% rownames(installed.packages()))) install.packages(\"Matrix\"); print(\"Matrix\")\n",
    "if(!(\"MLmetrics\" %in% rownames(installed.packages()))) install.packages(\"MLmetrics\"); print(\"MLmetrics\")\n",
    "if(!(\"monreg\" %in% rownames(installed.packages()))) install.packages(\"monreg\"); print(\"monreg\")\n",
    "if(!(\"nortest\" %in% rownames(installed.packages()))) install.packages(\"nortest\"); print(\"nortest\")\n",
    "if(!(\"RColorBrewer\" %in% rownames(installed.packages()))) install.packages(\"RColorBrewer\"); print(\"RColorBrewer\")\n",
    "if(!(\"recommenderlab\" %in% rownames(installed.packages()))) install.packages(\"recommenderlab\"); print(\"recommenderlab\")\n",
    "if(!(\"ROCR\" %in% rownames(installed.packages()))) install.packages(\"ROCR\"); print(\"ROCR\")\n",
    "if(!(\"pROC\" %in% rownames(installed.packages()))) install.packages(\"pROC\"); print(\"pROC\")\n",
    "if(!(\"Rcpp\" %in% rownames(installed.packages()))) install.packages(\"Rcpp\"); print(\"Rcpp\")\n",
    "if(!(\"scatterplot3d\" %in% rownames(installed.packages()))) install.packages(\"scatterplot3d\"); print(\"scatterplot3d\")\n",
    "if(!(\"stringr\" %in% rownames(installed.packages()))) install.packages(\"stringr\"); print(\"stringr\")\n",
    "if(!(\"sde\" %in% rownames(installed.packages()))) install.packages(\"sde\"); print(\"sde\")\n",
    "if(!(\"timeDate\" %in% rownames(installed.packages()))) install.packages(\"timeDate\"); print(\"timeDate\")\n",
    "if(!(\"tsoutliers\" %in% rownames(installed.packages()))) install.packages(\"tsoutliers\"); print(\"tsoutliers\")\n",
    "if(!(\"wordcloud\" %in% rownames(installed.packages()))) install.packages(\"wordcloud\"); print(\"wordcloud\")\n",
    "if(!(\"xgboost\" %in% rownames(installed.packages()))) install.packages(\"xgboost\"); print(\"xgboost\")\n",
    "for (pkg in c(\"RCurl\",\"jsonlite\")) if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }\n",
    "install.packages(\"h2o\", type = \"source\", repos = (c(\"http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotes::install_github('catboost/catboost', subdir = 'catboost/R-package')\n",
    "remotes::install_github('AdrianAntico/RemixAutoML', upgrade = FALSE, dependencies = FALSE, force = TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the currently installed packages\n",
    "installed.packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TicToc to measure code running time\n",
    "install.packages('tictoc', repos='http://cran.us.r-project.org')\n",
    "library(tictoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('graphics', repos='http://cran.us.r-project.org')\n",
    "library(graphics)\n",
    "\n",
    "# Added additional R libs (NOT used by this notebook) -pmh\n",
    "install.packages('ggplot2', repos='http://cran.us.r-project.org')\n",
    "library(ggplot2)\n",
    "\n",
    "install.packages('datasets', repos='http://cran.us.r-project.org')\n",
    "library(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "sagemaker <- import('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating and accessing the data storage</h3>\n",
    "\n",
    "The `Session` class provides operations for working with the following [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) resources with Amazon SageMaker:\n",
    "\n",
    "* [S3](https://boto3.readthedocs.io/en/latest/reference/services/s3.html)\n",
    "* [SageMaker](https://boto3.readthedocs.io/en/latest/reference/services/sagemaker.html)\n",
    "* [SageMakerRuntime](https://boto3.readthedocs.io/en/latest/reference/services/sagemaker-runtime.html)\n",
    "\n",
    "Let's create an [Amazon Simple Storage Service](https://aws.amazon.com/s3/) bucket for your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session <- sagemaker$Session()\n",
    "bucket <- session$default_bucket()\n",
    "\n",
    "print (paste(\"Default bucket name:\", bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** - The `default_bucket` function creates a unique Amazon S3 bucket with the following name: \n",
    "\n",
    "`sagemaker-<aws-region-name>-<aws account number>`\n",
    "\n",
    "Specify the IAM role's [ARN](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html) to allow Amazon SageMaker to access the Amazon S3 bucket. You can use the same IAM role used to create this Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn <- sagemaker$get_execution_role()\n",
    "\n",
    "print (paste(\"Role ARN:\",role_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Downloading and processing the dataset</h3>\n",
    "\n",
    "The model uses the [abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). First, download the data and start the [exploratory data analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis). Use tidyverse packages to read the data, plot the data, and transform the data into ML format for Amazon SageMaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)\n",
    "data_file <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data'\n",
    "abalone <- read_csv(file = data_file, col_names = FALSE)\n",
    "names(abalone) <- c('sex', 'length', 'diameter', 'height', 'whole_weight', 'shucked_weight', 'viscera_weight', 'shell_weight', 'rings')\n",
    "head(abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that `sex` is a factor data type but is currently a character data type (F is Female, M is male, and I is infant). Change `sex` to a factor and view the statistical summary of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone$sex <- as.factor(abalone$sex)\n",
    "summary(abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary above shows that the minimum value for `height` is 0.\n",
    "\n",
    "Visually explore which abalones have height equal to 0 by plotting the relationship between `rings` and `height` for each value of `sex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "options(repr.plot.width = 5, repr.plot.height = 4) \n",
    "ggplot(abalone, aes(x = height, y = rings, color = sex)) + geom_point() + geom_jitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use [RBokeh](https://hafen.github.io/rbokeh/) pachage to create interactive illustrations. According the documenation page:\n",
    "> \"*Bokeh is a visualization library that provides a flexible and powerful declarative framework for creating web-based plots. Bokeh renders plots using HTML canvas and provides many mechanisms for interactivity. Bokeh has interfaces in Python, Scala, Julia, and now R.*\"\n",
    "\n",
    "`rbokeh` comes standard with SageMaker's R kernel. You can import the library as follows:\n",
    "\n",
    ">`library(rbokeh)`\n",
    "\n",
    "Below is an exmaple of an interactive version of the above chart using RBokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import rbokeh\n",
    "library(rbokeh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p <- figure() %>%\n",
    "  ly_points(height, rings, data = abalone,\n",
    "    hover = list(height, rings))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows multiple outliers: two infant abalones with a height of 0 and a few female and male abalones with greater heights than the rest. Let's filter out the two infant abalones with a height of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "abalone <- abalone %>%\n",
    "  filter(height != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparing the dataset for model training</h3>\n",
    "\n",
    "The model needs three datasets: one each for training, testing, and validation. First, convert `sex` into a [dummy variable](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)) and move the target, `rings`, to the first column. Amazon SageMaker algorithm require the target to be in the first column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone <- abalone %>%\n",
    "  mutate(female = as.integer(ifelse(sex == 'F', 1, 0)),\n",
    "         male = as.integer(ifelse(sex == 'M', 1, 0)),\n",
    "         infant = as.integer(ifelse(sex == 'I', 1, 0))) %>%\n",
    "  select(-sex)\n",
    "abalone <- abalone %>%\n",
    "  select(rings:infant, length:shell_weight)\n",
    "head(abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, sample 70% of the data for training the ML algorithm. Split the remaining 30% into two halves, one for testing and one for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_train <- abalone %>%\n",
    "  sample_frac(size = 0.7)\n",
    "abalone <- anti_join(abalone, abalone_train)\n",
    "abalone_test <- abalone %>%\n",
    "  sample_frac(size = 0.5)\n",
    "abalone_valid <- anti_join(abalone, abalone_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the training and validation data to Amazon S3 so that you can train the model. First, write the training and validation datasets to the local filesystem in .csv format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(abalone_train, 'abalone_train.csv', col_names = FALSE)\n",
    "write_csv(abalone_valid, 'abalone_valid.csv', col_names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, upload the two datasets to the Amazon S3 bucket into the `data` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train <- session$upload_data(path = 'abalone_train.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')\n",
    "s3_valid <- session$upload_data(path = 'abalone_valid.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define the Amazon S3 input types for the Amazon SageMaker algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_input <- sagemaker$s3_input(s3_data = s3_train,\n",
    "                                     content_type = 'csv')\n",
    "s3_valid_input <- sagemaker$s3_input(s3_data = s3_valid,\n",
    "                                     content_type = 'csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training the model</h3>\n",
    "\n",
    "Amazon SageMaker algorithm are available via a [Docker](https://www.docker.com/) container. To train an [XGBoost](https://en.wikipedia.org/wiki/Xgboost) model, specify the training containers in [Amazon Elastic Container Registry](https://aws.amazon.com/ecr/) (Amazon ECR) for the AWS Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test access to registry for DeepAR Forecasting (NOT used in this notebook) - pmh\n",
    "registry <- sagemaker$amazon$amazon_estimator$registry(session$boto_region_name, algorithm='forecasting-deepar')\n",
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry <- sagemaker$amazon$amazon_estimator$registry(session$boto_region_name, algorithm='xgboost')\n",
    "registry\n",
    "\n",
    "XGBOOST_IMAGE = sagemaker$amazon$amazon_estimator$get_image_uri(session$boto_region_name, 'xgboost', repo_version='1.0-1')\n",
    "XGBOOST_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registry <- sagemaker$amazon$amazon_estimator$registry(session$boto_region_name, algorithm='xgboost')\n",
    "XGBOOST_IMAGE_WITH_TAG = sagemaker$amazon$amazon_estimator$get_image_uri(session$boto_region_name, 'xgboost', repo_version='1.0-1-cpu-py3')\n",
    "\n",
    "XGBOOST_IMAGE_WITH_TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use version ':1' to get stable version, use '$latest' for experimental\n",
    "# Testing version ':1.0-1' for multi-model version - failed\n",
    "# Testing version '1.0-1-cpu-py3' \n",
    "# container <- paste(registry, 'xgboost:1.0-1-cpu-py3', sep='/')\n",
    "\n",
    "#container <- paste(registry, 'sagemaker-xgboost:1.0-1-cpu-py3', sep='/')\n",
    "\n",
    "container = '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3'\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an Amazon SageMaker [Estimator](http://sagemaker.readthedocs.io/en/latest/estimators.html), which can train any supplied algorithm that has been containerized with Docker. When creating the Estimator, use the following arguments:\n",
    "* **image_name** - The container image to use for training\n",
    "* **role** - The Amazon SageMaker service role\n",
    "* **train_instance_count** - The number of Amazon EC2 instances to use for training\n",
    "* **train_instance_type** - The type of Amazon EC2 instance to use for training\n",
    "* **train_volume_size** - The size in GB of the [Amazon Elastic Block Store](https://aws.amazon.com/ebs/) (Amazon EBS) volume to use for storing input data during training\n",
    "* **train_max_run** - The timeout in seconds for training\n",
    "* **input_mode** - The input mode that the algorithm supports\n",
    "* **output_path** - The Amazon S3 location for saving the training results (model artifacts and output files)\n",
    "* **output_kms_key** - The [AWS Key Management Service](https://aws.amazon.com/kms/) (AWS KMS) key for encrypting the training output\n",
    "* **base_job_name** - The prefix for the name of the training job\n",
    "* **sagemaker_session** - The Session object that manages interactions with Amazon SageMaker API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output <- paste0('s3://', bucket, '/output')\n",
    "estimator <- sagemaker$estimator$Estimator(image_name = container,\n",
    "                                           role = role_arn,\n",
    "                                           train_instance_count = 1L,\n",
    "                                           train_instance_type = 'ml.m5.large',\n",
    "                                           train_volume_size = 30L,\n",
    "                                           train_max_run = 3600L,\n",
    "                                           input_mode = 'File',\n",
    "                                           output_path = s3_output,\n",
    "                                           output_kms_key = NULL,\n",
    "                                           base_job_name = NULL,\n",
    "                                           sagemaker_session = NULL,\n",
    "                                           enable_network_isolation = FALSE) # added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** - The equivalent to `None` in Python is `NULL` in R.\n",
    "\n",
    "Specify the [XGBoost hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) and fit the model. Set the number of rounds for training to 100 which is the default value when using the XGBoost library outside of Amazon SageMaker. Also specify the input data and a job name based on the current time stamp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Following Cell can take up to 5 minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic(\"Model Fitting\")\n",
    "\n",
    "estimator$set_hyperparameters(num_round = 100L)\n",
    "job_name <- paste('sagemaker-train-xgboost', format(Sys.time(), '%H-%M-%S'), sep = '-')\n",
    "input_data <- list('train' = s3_train_input,\n",
    "                   'validation' = s3_valid_input)\n",
    "\n",
    "estimator$fit(inputs = input_data,\n",
    "              job_name = job_name)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training has finished, Amazon SageMaker copies the model binary (a gzip tarball) to the specified Amazon S3 output location. Get the full Amazon S3 path with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator$model_data\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deploying the model</h3>\n",
    "\n",
    "Amazon SageMaker lets you [deploy your model](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html) by providing an endpoint that consumers can invoke by a secure and simple API call using an HTTPS request. Let's deploy our trained model to a `ml.t2.medium` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Following Cell can take up to 5 minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tic(\"Model Deployment\")\n",
    "#model_endpoint <- estimator$deploy(initial_instance_count = 1L,\n",
    "#                                   instance_type = 'ml.t2.medium')\n",
    "#toc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generating predictions with the model</h3>\n",
    "\n",
    "Use the test data to generate predictions. Pass comma-separated text to be serialized into JSON format by specifying `text/csv` and `csv_serializer` for the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_endpoint$content_type <- 'text/csv'\n",
    "#model_endpoint$serializer <- sagemaker$predictor$csv_serializer\n",
    "#model_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the target column and convert the first 500 observations to a matrix with no column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_test <- abalone_test[-1]\n",
    "num_predict_rows <- 500\n",
    "test_sample <- as.matrix(abalone_test[1:num_predict_rows, ])\n",
    "dimnames(test_sample)[[2]] <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note** - 500 observations was chosen because it doesn't exceed the endpoint limitation.\n",
    "\n",
    "Generate predictions from the endpoint and convert the returned comma-separated string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'stringr'\n",
    "library(stringr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the model endpoint via predict\n",
    "tic(\"Invoke Endpoint\")\n",
    "predictions <- model_endpoint$predict(test_sample)\n",
    "predictions <- str_split(predictions, pattern = ',', simplify = TRUE)\n",
    "predictions <- as.numeric(predictions)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column-bind the predicted rings to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to Integer\n",
    "abalone_test <- cbind(predicted_rings = as.integer(predictions), \n",
    "                      abalone_test[1:num_predict_rows, ])\n",
    "head(abalone_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional steps - creation of multi-variant endpoints\n",
    "\n",
    "The following steps demonstrate how to leverage more deployment options, including how to create Multi-Variant Endpoints, crearing the EndpointConfig structure that enables it, describing the endpoint, etc.\n",
    "\n",
    "All cells added by Paul Hargis are annotated with \"-pmh\" in the comment line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install paws package -pmh\n",
    "install.packages('paws')\n",
    "library(paws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a paws SageMaker session -pmh\n",
    "sm_client <- paws::sagemaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access info from the training job -pmh\n",
    "# Note: Cut/paste new training job name from SageMaker Dashboard\n",
    "\n",
    "# new_training_job_name = '<INSERT TRAINING JOB>'\n",
    "new_training_job_name = 'sagemaker-train-xgboost-22-27-51'\n",
    "info <- sm_client$describe_training_job(TrainingJobName=new_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the model artifacts -pmh\n",
    "model_artifacts <- info[['ModelArtifacts']]\n",
    "model_data <- model_artifacts[['S3ModelArtifacts']]\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_from_estimator = estimator$create_model(role=role_arn, image=container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model\n",
    "print(multi_model_from_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify new endpoint name -pmh\n",
    "ENDPOINT_CONFIG_NAME = 'MultiModelEndPointConfig'\n",
    "\n",
    "ENDPOINT_NAME = 'MultiModelEndpoint'\n",
    "ENDPOINT_INSTANCE_TYPE = 'ml.m4.xlarge'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify new model name -pmh\n",
    "#multi_variant_model_name = 'MultiVariantModel'\n",
    "\n",
    "mme_model_name = \"mme-model-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create primary container -pmh\n",
    "primary_container <- vector(mode=\"list\", length=3)\n",
    "names(primary_container) <- c('Image', 'ModelDataUrl','Mode')      \n",
    "\n",
    "primary_container[[1]] <- container\n",
    "primary_container[[2]] <- model_data\n",
    "primary_container[[3]] <- 'MultiModel'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is references the AWS managed XGBoost container\n",
    "#XGBOOST_IMAGE = sagemaker$amazon$amazon_estimator$get_image_uri(session$boto_region_name, 'xgboost', repo_version='latest')\n",
    "\n",
    "# confirm value of container\n",
    "primary_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model for multi-variants -pmh\n",
    "#mme_model <- sm_client$create_model(\n",
    "#    ModelName = mme_model_name,\n",
    "#    ExecutionRoleArn = role_arn,\n",
    "#    PrimaryContainer = primary_container)\n",
    "\n",
    "#print(paste('MME model ARN: ', mme_model[['ModelArn']]))\n",
    "#print(mme_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new endpoint configuration for MultiModel -pmh\n",
    "prod_variant_vector <- vector(mode=\"list\", length=5)\n",
    "names(prod_variant_vector) <- c('VariantName', 'ModelName', 'InitialInstanceCount', 'InstanceType', 'InitialVariantWeight')\n",
    "\n",
    "prod_variant_vector[[1]] <- 'AllTraffic'\n",
    "prod_variant_vector[[2]] <- mme_model_name\n",
    "prod_variant_vector[[3]] <- 1L\n",
    "prod_variant_vector[[4]] <- 'ml.t2.medium'\n",
    "prod_variant_vector[[5]] <- 1L\n",
    "\n",
    "prod_variant_vector\n",
    "\n",
    "prod_variant_list <- vector(mode=\"list\", length=1)\n",
    "prod_variant_list[[1]] = prod_variant_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new endpoint config that supports MultiModel deployments -pmh\n",
    "response = sm_client$create_endpoint_config(\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    "    ProductionVariants=prod_variant_list)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-variant Endpoint -pmh\n",
    "multi_model_endpoint = sm_client$create_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_NAME\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe new endpoint, viewing the $EndpointStatus element...\n",
    "# Re-run this cell until it's status reads -> \"InService\"  -pmh\n",
    "endpoint_desc = sm_client$describe_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME\n",
    ")\n",
    "\n",
    "endpoint_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to create Multi-Model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where our MME will read models from on S3.\n",
    "DEFAULT_BUCKET <- bucket\n",
    "DATA_PREFIX <- '/multi_model_artifacts/models'\n",
    "\n",
    "model_data_prefix = paste('s3://', DEFAULT_BUCKET, DATA_PREFIX, sep='')\n",
    "model_data_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mme_model <- estimator$create_model(role=role_arn, image=container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump MME Model\n",
    "print(mme_model_name)\n",
    "print(model_data_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(multi_model_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data_model <- sagemaker$multidatamodel$MultiDataModel(\n",
    "                        name=mme_model_name,\n",
    "                        model_data_prefix=model_data_prefix,\n",
    "                        model=multi_model_from_estimator, # passing our model - passes container image needed for the endpoint\n",
    "                        sagemaker_session=session)\n",
    "multi_data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = multi_data_model$deploy(initial_instance_count=1,\n",
    "                       instance_type=ENDPOINT_INSTANCE_TYPE,\n",
    "                       endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List active models - should be none\n",
    "list(multi_data_model$list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from estimator\n",
    "#artifact_path = estimator$latest_training_job$describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "artifact_path = model_data\n",
    "print(paste('Model Artifact Loc:', artifact_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = artifact_path.split('/')[-4]+'.tar.gz'\n",
    "model_name = 'mme-model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is copying over the model artifact to the S3 location for the MME.\n",
    "multi_data_model$add_model(model_data_source=artifact_path, model_data_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multi_data_model$list_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator$model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run test of multi-variant prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add content-type and serializer -pmh\n",
    "multi_model_endpoint$content_type <- 'text/csv'\n",
    "multi_model_endpoint$serializer <- sagemaker$predictor$csv_serializer\n",
    "\n",
    "multi_model_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_test <- abalone_test[-1]\n",
    "num_predict_rows <- 500\n",
    "test_sample <- as.matrix(abalone_test[1:num_predict_rows, ])\n",
    "dimnames(test_sample)[[2]] <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump test sample\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample <- abalone_test[1,]\n",
    "single_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_sample = '1,0,0,0.44,0.345,0.17,0.4085,0.15,0.0825,0.1515'\n",
    "csv_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker runtime\n",
    "runtime_sagemaker = paws::sagemakerruntime();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_response <- runtime_sagemaker$invoke_endpoint(\n",
    "    EndpointName = multi_model_endpoint,\n",
    "    ContentType = 'text/csv',\n",
    "    # TargetModel=mme_model,\n",
    "    Body = csv_sample,\n",
    "    )\n",
    "\n",
    "runtime_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deleting the endpoint</h3>\n",
    "\n",
    "When you're done with the model, delete the endpoint to avoid incurring deployment costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session$delete_endpoint(model_endpoint$endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
